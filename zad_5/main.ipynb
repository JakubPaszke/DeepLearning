{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f261bda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "from datasets import load_dataset\n",
    "from seqeval.metrics import classification_report, f1_score, precision_score, recall_score\n",
    "from tqdm import tqdm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e9df642",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"conll2003\", trust_remote_code=True)\n",
    "\n",
    "model_name = \"dslim/bert-base-NER\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b61c9889",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7850a805",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(example):\n",
    "    tokens = example[\"tokens\"]\n",
    "    labels = example[\"ner_tags\"]\n",
    "\n",
    "    tokenized_inputs = tokenizer(tokens, is_split_into_words=True, truncation=True, return_offsets_mapping=True)\n",
    "    word_ids = tokenized_inputs.word_ids()\n",
    "\n",
    "    aligned_labels = []\n",
    "    previous_word_idx = None\n",
    "    for word_idx in word_ids:\n",
    "        if word_idx is None:\n",
    "            aligned_labels.append(\"O\")\n",
    "        elif word_idx != previous_word_idx:\n",
    "            label = dataset[\"train\"].features[\"ner_tags\"].feature.names[labels[word_idx]]\n",
    "            aligned_labels.append(label)\n",
    "        else:\n",
    "            label = dataset[\"train\"].features[\"ner_tags\"].feature.names[labels[word_idx]]\n",
    "            if label.startswith(\"B-\"):\n",
    "                label = label.replace(\"B-\", \"I-\")\n",
    "            aligned_labels.append(label)\n",
    "        previous_word_idx = word_idx\n",
    "\n",
    "    return tokenized_inputs, aligned_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a72be01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3250/3250 [03:54<00:00, 13.87it/s]\n"
     ]
    }
   ],
   "source": [
    "true_labels = []\n",
    "pred_labels = []\n",
    "\n",
    "label_list = model.config.id2label\n",
    "\n",
    "for example in tqdm(dataset[\"validation\"]):\n",
    "    tokens = example[\"tokens\"]\n",
    "    labels = example[\"ner_tags\"]\n",
    "\n",
    "    tokenized_inputs = tokenizer(tokens, is_split_into_words=True, return_tensors=\"pt\", truncation=True)\n",
    "    with torch.no_grad():\n",
    "        output = model(**tokenized_inputs).logits\n",
    "\n",
    "    predictions = torch.argmax(output, dim=2).squeeze().tolist()\n",
    "    word_ids = tokenized_inputs.word_ids()\n",
    "\n",
    "    aligned_preds = []\n",
    "    aligned_labels = []\n",
    "\n",
    "    prev_word_idx = None\n",
    "    for idx, word_idx in enumerate(word_ids):\n",
    "        if word_idx is None:\n",
    "            continue\n",
    "        if word_idx != prev_word_idx:\n",
    "            aligned_preds.append(label_list[predictions[idx]])\n",
    "            label = dataset[\"validation\"].features[\"ner_tags\"].feature.names[labels[word_idx]]\n",
    "            aligned_labels.append(label)\n",
    "        prev_word_idx = word_idx\n",
    "\n",
    "    pred_labels.append(aligned_preds)\n",
    "    true_labels.append(aligned_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b4a1590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         LOC       0.98      0.97      0.97      1837\n",
      "        MISC       0.90      0.91      0.91       922\n",
      "         ORG       0.93      0.93      0.93      1341\n",
      "         PER       0.96      0.98      0.97      1842\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      5942\n",
      "   macro avg       0.94      0.95      0.94      5942\n",
      "weighted avg       0.95      0.95      0.95      5942\n",
      "\n",
      "F1 Score: 0.9515\n",
      "Precision: 0.9494\n",
      "Recall: 0.9536\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report:\")\n",
    "print(classification_report(true_labels, pred_labels))\n",
    "print(f\"F1 Score: {f1_score(true_labels, pred_labels):.4f}\")\n",
    "print(f\"Precision: {precision_score(true_labels, pred_labels):.4f}\")\n",
    "print(f\"Recall: {recall_score(true_labels, pred_labels):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
